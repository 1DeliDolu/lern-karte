# 🧩 3.2 Daten bewerten und aus verschiedenen Datenquellen zusammenführen [Seite: 164]

In diesem Abschnitt wird erläutert, wie Unternehmen große Datenmengen unterschiedlicher Herkunft bewerten, analysieren und zusammenführen, um daraus qualitativ hochwertige Informationen zu gewinnen.

---

## 📊 Bedeutung und Zielsetzung

Unternehmen erzeugen vielfältige **Datenquellen** – etwa Kundendaten, Sensordaten oder Transaktionsdaten. Diese Daten sind oft **heterogen** und nicht zentral zugänglich. Ziel moderner Softwarelösungen ist die **Integration dieser Quellen** und die **Bewertung der Datenqualität**, um sie effektiv nutzbar zu machen.

---

## 🧮 3.2.1 Die Qualität von Daten beschreiben

| Begriff                     | Definition                                                                                    |
| :-------------------------- | :-------------------------------------------------------------------------------------------- |
| **Datenqualität**           | Maß für die Eignung von Daten, um Informationsbedürfnisse zu erfüllen.                        |
| **Datenqualitätssicherung** | Prozess der Analyse, Bereinigung und Überwachung von Datenbeständen, um Fehler zu minimieren. |

### 🔍 Qualitätskriterien für Daten

Die Datenqualität wird mithilfe verschiedener Kriterien beurteilt:

| Kriterium             | Bedeutung                                   | Beispiel                                      |
| :-------------------- | :------------------------------------------ | :-------------------------------------------- |
| **Vollständigkeit**   | Alle Attribute enthalten gültige Werte.     | Fehlendes Geburtsdatum = unvollständig        |
| **Eindeutigkeit**     | Jeder Datensatz ist eindeutig.              | Doppelte Kundendaten („Dublette“)             |
| **Korrektheit**       | Werte stimmen mit der Realität überein.     | Unplausibles Geburtsjahr 1900                 |
| **Aktualität**        | Daten entsprechen dem aktuellen Stand.      | Alte Adressen                                 |
| **Genauigkeit**       | Werte haben die nötige Präzision.           | Messdaten mit unzureichenden Nachkommastellen |
| **Konsistenz**        | Daten sind widerspruchsfrei.                | Preis × Anzahl ≠ Gesamtbetrag                 |
| **Redundanzfreiheit** | Keine doppelten Informationen.              | Doppelte Kundennummern                        |
| **Relevanz**          | Daten entsprechen dem Analysezweck.         | Umsätze außerhalb des Zielquartals            |
| **Einheitlichkeit**   | Gleiche Daten sind gleich formatiert.       | Unterschiedliche Datumsformate                |
| **Zuverlässigkeit**   | Herkunft und Qualität sind nachvollziehbar. | Anteil verlässlicher Datenquellen             |
| **Verständlichkeit**  | Daten sind für Nutzer klar interpretierbar. | Modellnummer vs. Produktname                  |
| **Zugänglichkeit**    | Daten sind leicht abrufbar.                 | Online-Zugriff auf Bestelldaten               |

### 🔄 Prozess zur Verbesserung der Datenqualität

1. **Analyse (Data Profiling)** – Erkennen von Fehlern und Widersprüchen.
2. **Bereinigung (Data Cleaning)** – Entfernen oder Korrigieren fehlerhafter Daten.
3. **Monitoring (Data Monitoring)** – Regelmäßige Kontrolle zur langfristigen Qualitätssicherung.

> ❗ **Datenalterung**: Qualität nimmt mit der Zeit ab (z. B. Adressänderungen). Regelmäßige Überprüfung ist daher erforderlich.

---

## 🌐 3.2.2 Daten aus Datenquellen abrufen

### 📁 Arten von Datenquellen

* **Primäre Quellen**: Ursprungsort der Daten (z. B. Sensoren, Benutzer).
* **Sekundäre Quellen**: Speicherorte (z. B. Datenbanken, Dateien).

Datenquellen können **offen (Open Data)** oder **geschlossen (Closed Data)** sein.

| Aspekt           | Open Data          | Closed Data                     |
| :--------------- | :----------------- | :------------------------------ |
| **Zugang**       | Öffentlich         | Beschränkt                      |
| **Verarbeitung** | Einfach maschinell | Oft analog/schwer zugänglich    |
| **Kosten**       | Kostenlos          | Kostenpflichtig                 |
| **Rechte**       | Frei verwendbar    | Einschränkungen / Urheberrechte |

### ⚙️ Gängige Datenformate zur Datenübertragung

| Format   | Beschreibung                                          | Kennzeichen                   |
| :------- | :---------------------------------------------------- | :---------------------------- |
| **CSV**  | Einfache Textdatei, Werte durch Separator getrennt.   | `;` oder `,` als Trennzeichen |
| **XML**  | Hierarchische Datenstruktur mit **Tags**.             | `<Tag>Inhalt</Tag>`           |
| **JSON** | Schlüssel-Wert-Struktur, kompakt und leichtgewichtig. | `{ "Name": "Max" }`           |

### 🔐 Datenzugriff und -übertragung

Daten werden über **Netzwerkprotokolle** abgerufen:

* **FTP / SFTP / FTPS** – Dateiübertragung
* **HTTP / HTTPS** – Webzugriff
* **SOAP** – komplexes, XML-basiertes Standardprotokoll
* **REST** – moderne, ressourcenschonende API-Technologie (mit HTTP-Methoden `GET`, `POST`, `PUT`, `DELETE`)

| Vergleich       | SOAP                 | REST                    |
| :-------------- | :------------------- | :---------------------- |
| **Struktur**    | XML-basiert, formell | JSON/andere Formate     |
| **Komplexität** | Hoch                 | Einfach                 |
| **Sicherheit**  | Integriert (ACID)    | Über HTTPS möglich      |
| **Einsatz**     | Unternehmenssysteme  | Web-/Cloud-/Mobile-Apps |

---

## 🔗 3.2.3 Daten heterogener Datenquellen zusammenführen

### 🧠 Begriff und Ziel

**Informationsintegration** bedeutet, Daten aus unterschiedlichen, oft inkompatiblen Quellen in eine **gemeinsame Struktur** zu überführen.

### 🧩 Formen der Heterogenität

| Form            | Beschreibung                            | Beispiel                             |
| :-------------- | :-------------------------------------- | :----------------------------------- |
| **Technisch**   | Unterschiedliche Zugriffsschnittstellen | XPath vs. SQL                        |
| **Syntaktisch** | Verschiedene Formate                    | `20.03.2021` vs. `2021-03-20`        |
| **Datenmodell** | Unterschiedliche Strukturen             | Relational vs. dokumentenbasiert     |
| **Strukturell** | Abweichende Tabellendesigns             | Adresse eingebettet oder ausgelagert |
| **Semantisch**  | Unterschiedliche Bedeutung              | „Ort“ vs. „Location“                 |

### 🧱 Integrationsarten

| Art                                         | Beschreibung                                           | Beispiele                         | Vorteile / Nachteile                                |
| :------------------------------------------ | :----------------------------------------------------- | :-------------------------------- | :-------------------------------------------------- |
| **Physische (materialisierte) Integration** | Daten werden zentral gesammelt.                        | **Data Warehouse**, **Data Lake** | Schnell, hohe Qualität / nicht immer aktuell        |
| **Virtuelle (logische) Integration**        | Daten bleiben in Ursprungsquellen; Zugriff bei Bedarf. | **föderierte Datenbanksysteme**   | Immer aktuell / Abfragen langsam, Qualität geringer |

### 🏗️ Data Warehouse

* Zentrale, strukturierte Datenspeicherung.
* Bereitstellung für **Analysen und Reports**.
* Optimiert für **strukturierte Daten**.

### 🌊 Data Lake

* Speicherung großer, **unstrukturierter Datenmengen**.
* Hohe Flexibilität für **Big Data** und **Machine Learning**.
* Moderne Analysetechniken ermöglichen Echtzeitauswertung.

> 💡 **Data Virtualization**: Kombination der Vorteile beider Ansätze – Daten bleiben an ihrem Ursprungsort, werden aber virtuell integriert und sind stets aktuell.

---

### 🧾 Zusammenfassung

* **Datenqualität** ist Basis für valide Analysen.
* **Kriterien** wie Vollständigkeit, Konsistenz, Genauigkeit sind messbar.
* **Prozesse**: Analyse → Bereinigung → Monitoring.
* **Formate und Protokolle** ermöglichen den Austausch zwischen Systemen.
* **Informationsintegration** führt heterogene Daten in einheitliche Strukturen zusammen (Data Warehouse, Data Lake, Virtualisierung).

---

Diese strukturierte Übersicht bietet einen vollständigen und didaktisch klaren Überblick über Kapitel **3.2 „Daten bewerten und aus verschiedenen Datenquellen zusammenführen“**.
