# 3.2.3 Daten aufbereiten [Seite: 232]

**Kernaussage:** Heterogene Rohdaten werden für ML-Verfahren systematisch in **maschinenlesbare**, **vergleichbare** und **kompakte** Repräsentationen überführt. Zentrale Schritte: **Codierung**, **Vereinheitlichung**, **Reduzierung**, **Konvertierung** und **Klassifizierung**.

## Methoden der Datenaufbereitung (Überblick)

* **Codierung:** Daten digitalisieren bzw. in einheitliche **Zeichensätze/Formate** überführen. 
* **Vereinheitlichung:** Formate und Strukturen aus unterschiedlichen Quellen **angleichen** (vergleichbares Zielformat).
* **Reduzierung:** Informationen auf das **Wesentliche** verdichten (z. B. Farbinformationen weglassen; optional **Hashing** mit ähnlichen Ausgangsdaten → ähnlichen Werten).
* **Konvertierung:** Daten in **problemadäquate Zielformate** transformieren.
* **Klassifizierung:** Daten in **Kategorien** einteilen (Vorbereitung bzw. Teil der späteren Lernverfahren).

## Werkzeuge (Auswahl)

* **Anaconda:** Distribution inkl. **Jupyter Notebook**, **pandas**, **Matplotlib** für Analyse & Aufbereitung.
* **NumPy/SciPy:** effiziente **Vektor-/Matrix**-Operationen, umfangreiche **Statistik**.
* **Beautiful Soup:** **Webseiten** auslesen/verarbeiten (HTML/XML/Markdown).
* **NLTK:** **Sprachverarbeitung** (Tokenisierung, Stoppwörter etc.).
* **OpenCV:** **Bildverarbeitung** und **Bildklassifikation**-Funktionen.

## Spezifika nach Datentyp

### Texte

* **Codierung:** Einheitlicher **Zeichensatz** (z. B. UTF-8).
* **Vereinheitlichung:** **Strukturangaben** (HTML, Format-Tags) entfernen.
* **Reduzierung/Konvertierung:** Satz-/Leerzeichen bereinigen, **Bag-of-Words** bilden; **Bi-/Trigramme** zur Kontextberücksichtigung.
* **Sprachliche Vorverarbeitung:** **Tokenisierung**, **Lemmatisierung**, **Kleinschreibung**, **Stoppwörter** entfernen.

### Bilder

* **Codierung:** Einheitliche **Bildformate**.
* **Vereinheitlichung:** Gleiche **Größe**, **Auflösung**, **Farbtiefe**.
* **Reduzierung/Konvertierung:** **Größenreduktion**, ggf. **Graustufen**, **Ausschnittwahl**.

## Praxisbeispiel: Chatbot „Yachthafen Resort“

Ziel: Website-Texte zu Wellnessangeboten für den Chatbot nutzbar machen. Vorgehen:

1. **Quellenzugriff:** HTML einlesen bzw. **Webscraping**; relevante Inhalte extrahieren (z. B. `input`-Felder).
2. **Bereinigung/Normalisierung:** Leerzeichen/Zeilenumbrüche entfernen; einheitliche Bezeichner.
3. **Sprachliche Aufbereitung:** **Tokenisieren**, **Lemmatisieren** (z. B. HanoverTagger), **Stoppwörter** entfernen, **Kleinschreibung**.
4. **Konvertierung:** Ergebnis in geeignetes **Listen/Array**-Format für die weitere Verarbeitung.

## Hinweise zur Qualität & Effizienz

* **Früh reduzieren**, um Rechenaufwand zu senken; bei Bildern ggf. **Graustufen**/Crop, bei Texten **BoW**/**n-Gramme**.
* **Einheitliche Formate** erleichtern **Vergleichbarkeit** und **Pipeline-Automatisierung**. 
* **Hashing** kann große Eingaben kompakt und **vergleichbar** machen (ähnliche Inputs → ähnliche Hashwerte). 

## Merksätze

* **Datenaufbereitung ist Pflichtprogramm:** Ohne **Codierung**, **Vereinheitlichung** und **Reduzierung** kein robustes ML. 
* **Werkzeuge gezielt kombinieren:** **Anaconda** + **NumPy/SciPy** + **Beautiful Soup/NLTK/OpenCV** decken typische Text-/Bild-Pipelines ab.
* **Aufgabenspezifisch denken:** Aufbereitung immer am **Zielproblem** ausrichten (Feature-Nützlichkeit > Rohdatenfülle). 

---

## [Nächstes](../3.3_Regelbasierte_Verfahren_zum_maschinellen_Lernen_einsetzen/)