# 3.4 Künstliche neuronale Netze zum maschinellen Lernen einsetzen [Seite: 242]

Künstliche neuronale Netze (**KNN**) werden eingesetzt, wenn komplexe Problemstellungen nicht mehr sinnvoll durch **regelbasierte** Verfahren lösbar sind. Sie „lernen“ aus Beispielen, indem sie **Parameter/Gewichte** anpassen, und können so auf neue Situationen reagieren. Als durchgehendes Beispiel dient die **Klimaüberwachung** in der Bootsreparaturhalle (Feuchtigkeitssensor, kritische Werte erkennen und melden). 

## Grundidee und Nutzen

* **Deep Learning** nutzt Bild-, Audio-, Text- oder Zahlendaten (oft **unstrukturiert**) und extrahiert **Muster**, die auf unbekannte Fälle übertragen werden.
* **Lernen** bedeutet: fortlaufende **Optimierung** der Gewichte anhand von Erfolgen/Misserfolgen (Fehlermaß).
* Ergebnischarakter: **Prognose/Schätzung**, keine absolute Aussage; **Fehler** müssen vor Produktionseinsatz bewertet werden.

## Aufbau eines KNN

* **Neuron**: berechnet aus gewichteter Eingabe (x_i \cdot w_i) und **Schwellwert** (b) einen Ausgabewert (z. B. via **Aktivierungsfunktion**).
* **Verbindungen/Gewichte**: gerichtete Kanten, bestimmen Einflussstärke.
* **Schichten**: **Eingangsschicht**, **versteckte Schicht(en)**, **Ausgangsschicht**; mehr Schichten ⇒ „**tief**“.
* **Beispiel**: Einschichtiges **Perzeptron** entscheidet, ob **Feuchtigkeit ≥ 85** als „kritisch“ gilt.

## Typen neuronaler Netze (Auswahl)

* **Perzeptron**: einfachstes, schwellenwertbasiertes Netz.
* **Feed Forward Neural Network (FFNN)**: keine Zyklen; für **einfachere** Aufgaben.
* **Convolutional Neural Network (CNN)**: spezielle **Convolutional Layers** erhalten **räumliche Nachbarschaften**; stark für **Bild/Audio**.
* **Recurrent Neural Network (RNN)**: **Rückkopplungen** (direkt, seitlich, indirekt) ermöglichen **Zustandsspeicherung**; mächtig, aber **schwer zu trainieren**.

## Prozess: Von der Idee zum einsatzfähigen Modell

1. **Architektur auswählen** (passend zum Problem).
2. **Netz erstellen** (Schichten/Neuronen/Gewichte initialisieren).
3. **Trainieren** (Gewichte/Schwellwerte anpassen).
4. **Anwenden** (auf neue Daten).
5. **Bewerten** (Güte, Stabilität, **Konvergenz** prüfen).

## Lernverfahren

* **Supervised Learning**: Trainingsdaten enthalten **Eingaben + Zielausgabe**; Fehler wird rückwärts propagiert und **Parameter** werden angepasst.
* **Unsupervised Learning**: findet **Strukturen/Cluster** ohne Zielausgabe.
* **Reinforced Learning**: **Feedback/Belohnung** nach Entscheidungen.
* **Stochastical Learning**: zufällige **Parametervariationen** und Vergleich.

## Training & Evaluierung in der Beispielaufgabe

* **Ziel**: Feuchtigkeitswert (0–100) als **„kritisch“** (≥ 85) klassifizieren.
* **Supervised Learning** mit gelabelten Beispielen; wiederholte **Epochen** reduzieren den **Fehler**.
* **Konvergenz** beobachten: Fehler sollte **monoton sinken**; bei Nicht-Konvergenz **Architektur** oder **Daten** anpassen.

## Werkzeuge für Deep Learning

* **TensorFlow** (Google, Open Source): sehr **umfangreich**, verbreitet in **Unternehmensanwendungen**; mit **TensorFlow Lite** für ressourcenarme Geräte.
* **Keras**: benutzerfreundliche **High-Level-API**, heute integraler Teil von TensorFlow.
* **PyTorch** (Meta/Facebook): dynamische Definition bei Verwendung; verbreitet im **akademischen Umfeld**.
* **Teachable Machine**: browserbasiertes **No-Code-Training** für einfache Bild-/Gestenmodelle.
* **ONNX**: **Austauschformat** für Modelle zwischen Frameworks.
* **Data Version Control (DVC)**: **Versionierung** großer **Daten** und **Modelle**.

## TensorFlow/Keras – Minimalbeispiel (Konzept)

* **Tensor**: mehrdimensionale **Matrizen** als Ein-/Zwischen-/Ausgaben.
* **Modellaufbau**: **Sequential-Modell** mit **Dense**-Schicht (z. B. **Sigmoid**).
* **Training**: **binary_crossentropy** als Verlust, **RMSprop** als Optimierer; nach vielen **Epochen** trennt das Modell „< 85“ vs. „≥ 85“ korrekt; **Accuracy** wird evaluiert.

## Qualitäts- und Ethikaspekte (implizit fortgeführt)

* Ergebnisse sind **fehlertolerant** zu interpretieren; vor Einsatz **Fehlerbudget** und **Grenzfälle** prüfen.
* **Nachvollziehbarkeit** sinkt mit Framework-Komplexität (Stichwort **Black-Box**); Offenlegung/Erklärbarkeit wo möglich anstreben.

## Merksätze

* **Datenqualität** + passende **Architektur** ⇒ entscheidend für **Trainingserfolg**.
* **Konvergenz** ist Voraussetzung für **verlässliche** Anwendung.
* Auswahl von **Frameworks** richtet sich nach **Zielgruppe**, **Infrastruktur** und **Nachvollziehbarkeitsanforderungen**. 



---

## [Nächstes](./3.4.1_Aufbau_und_Funktionsweise_kuenstlicher_neuronaler_Netze_beschreiben.md)