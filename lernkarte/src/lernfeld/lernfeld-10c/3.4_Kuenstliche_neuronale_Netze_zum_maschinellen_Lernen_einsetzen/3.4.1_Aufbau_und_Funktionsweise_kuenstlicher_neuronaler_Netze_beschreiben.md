# 3.4.1 Aufbau und Funktionsweise künstlicher neuronaler Netze beschreiben [Seite: 242]

Künstliche neuronale Netze (**KNN**) ahmen die Funktionsweise des menschlichen Gehirns nach: Viele einfache **Neuronen** sind über gewichtete **Verbindungen** verknüpft und in **Schichten** organisiert. Aus Eingabewerten wird über gewichtete Summen, **Schwellenwerte**/**Bias** und eine **Aktivierungsfunktion** ein Ausgabewert berechnet. Je mehr (versteckte) Schichten, desto „**tiefer**“ das Netz. 

## Bestandteile eines KNN

* **Neuron**: Berechnet aus Eingaben (x_i) und **Gewichten** (w_i) eine Summe und vergleicht sie mit einem **Schwellenwert**/**Bias**; die Ausgabe entsteht über eine **Aktivierungsfunktion**. 
* **Verbindung (Synapse)**: Transportiert den Ausgabewert eines Neurons – skaliert durch ein **Gewicht** – als Eingabe zum nächsten Neuron. 
* **Schichten**: **Eingangsschicht**, eine oder mehrere **versteckte Schichten**, **Ausgangsschicht**; Anzahl der Neuronen in Ein-/Ausgangsschicht entspricht der Zahl der Ein-/Ausgabewerte. 

## Netztypen (Überblick)

* **Perzeptron**: Einfachstes Netz; Neuronen „feuern“ beim Überschreiten eines **Schwellenwerts**. Eignet sich für sehr einfache Klassifikationen. 
* **Feed-Forward Neural Network (FFNN)**: Azyklisch; umfasst ein- und mehrschichtige Perzeptrons; für **einfachere Problemstellungen**. 
* **Convolutional Neural Network (CNN)**: Spezielle **Convolutional Layers** erhalten **räumliche Nachbarschaften** (z. B. in Bildern); stark für **Bild-/Audiodaten**. 
* **Recurrent Neural Network (RNN)**: **Rückkopplungen** (direkt/seitlich/indirekt) erlauben **Zustandsspeicherung**; **mächtig**, aber **schwer zu trainieren**. 

## Funktionsweise – Prozessschritte

1. **Auswählen**: Passende **Netzarchitektur** wählen (z. B. Perzeptron, CNN, RNN).
2. **Erstellen**: Netz im Arbeitsspeicher instanziieren (Schichten, Neuronen, Verbindungen).
3. **Trainieren**: **Gewichte**/**Schwellenwerte** mit einem **Lernverfahren** anpassen.
4. **Anwenden**: Trainiertes Netz auf neue Fälle ausführen (Inference).
5. **Bewerten**: Ergebnisse prüfen und ggf. **Architektur**/**Daten**/**Training** anpassen. 

## Lernverfahren (Kernvarianten)

* **Supervised Learning**: Trainingsdaten mit **Eingabe + Zielausgabe**; Fehler wird berechnet und zur **Parameteranpassung** genutzt (z. B. Backpropagation). 
* **Unsupervised Learning**: Strukturentdeckung in reinen Eingaben (z. B. **Clustering**). 
* **Reinforced Learning**: Lernen über **Feedback/Belohnungen** nach Entscheidungen. 
* **Stochastical Learning**: **Zufällige** Parameterwahl und Ergebnisvergleich. 

## Beispiel (einstufiges **Perzeptron**)

* **Aufgabe**: Klimaüberwachung in einer **Bootsreparaturhalle**; Feuchtigkeitssensor liefert 0–100, **kritisch** ab **≥ 85**.
* **Modell**: Ein Eingang- und ein Ausgangsneuron (**einschichtiges Perzeptron**); Entscheidung „kritisch/nicht kritisch“ über **Schwelle** und **Gewichte**. 

## Training, Konvergenz und Ergebnisbewertung

* **Trainieren** passt **Gewichte/Schwellenwerte** iterativ an; die **Qualität** hängt maßgeblich von **Art** und **Qualität** der **Trainingsdaten** ab. 
* KNN liefern **Prognosen/Schätzungen**, keine absoluten Wahrheiten; **Fehler** sind vor Produktionseinsatz zu **quantifizieren**. 
* **Konvergenz**: Mit jeder **Epoche** sollte der Fehler sinken; bei Nicht-Konvergenz **Architektur** oder **Daten** überarbeiten. 

## Merksätze

* **Struktur** (Architektur) + **Datenqualität** bestimmen den Lernerfolg. 
* **Perzeptron/FFNN** für einfache, **CNN** für räumliche Daten, **RNN** für Sequenzen/Zustände. 
* **Bewertung** und **Konvergenzprüfung** sind unverzichtbar vor dem Einsatz. 

---

## [Nächstes](./3.4.2_Werkzeuge_fuer_Deep-Learning-Verfahren_auswaehlen.md)